# AIIJC Solution 2023

- *Написано*: Жамков Никита Д.
- tg: https://t.me/jeberkarawita
- GitHub: https://github.com/plugg1N/

<br />

# Выбор задания для решения:

Из всех рассмотренных мною заданий, самым интересным оказался вариант номер №5, так как задание - самое банальное:

1. Скачать .csv файлы
2. Провести анализ данных
3. Рефакторинг
4. Подбор и файн-тюн модели **до безумия**

![](https://github.com/plugg1N/aiijc-team-task-2023/blob/main/Images/excalidraw.png?raw=true)
___

# Какое там задание?

Как оказалось, нужно искать данный y. Задача типичной **бинарной классификации**. Либо 1.0, либо 0.0. Нужно научится различать - будет ли срыв заказа, или нет [Сайт](https://aiijc.com/ru/task/1517/)

Нам даны: два .csv файла - train и test

- *Test* мы не трогаем, так как там данные для отправки решения
- *Train* мы должны разбить на train и validation выборки, дабы постоянно узнавать, насколько хорошо работает наша модель



___
# Перейдем к решению:

<br />

## Рассматриваем данные

Загружаем .csv файл и начинаем смотреть на данные факторы и объекты

![](https://github.com/plugg1N/aiijc-team-task-2023/blob/main/Images/data1.png?raw=true)

Можно заметить, что у нас ОЧЕНЬ много колонок (факторов). Скорее всего, многие из них - **нас не интересуют**

Давайте взглянем на разницу между значениями 1 и 0 в *y* факторе, который мы пытаемся предсказать, чтобы не портить метрику, которая нас интересует: **F1-score**

![](https://github.com/plugg1N/aiijc-team-task-2023/blob/main/Images/big_bars.png?raw=true)

Разница безумная. Если начать обучение модели с такой разностью в классах, то наша модель станет `biased`, то есть она будет привязана к единому мнению о том, что *нули* попадаются чаще, чем единицы, и будет, в большинстве случаев, отдавать предпочтение именно одному классу, что испортит `Recall`, и **F1-score** впоследствии

> *Очень важно будет дополнить недостающий класс синтетическими значениями, при помощи ADASYN. Значимость дисбаланса в классах можно заметить, проанализировав формулы метрик*

$$ \Large F_1 \text -Score = 2 * \frac {\text precision * recall} {\text precision + recall} = \frac {TP} {TP + \frac {1} {2} (FP + FN)} $$
 
Можно заметить, что `recall` играет важную роль в расчете $F_1 \text-Score$, так как `recall` находится в числителе, умножается на два и на `precision`. Если он будет слишком маленьким, то хуже станет абсолютно весь $F_1 \text-Score$

<br />

## Feature-engineering

После того, как мы рассмотрели данные, нам стоит понять, какие факторы убрать из расчета

- Посмотрим на [корреляцию](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html) других факторов и y:
![](https://github.com/plugg1N/aiijc-team-task-2023/blob/main/Images/corr1.png?raw=true)

> *Мы можем заметить, что многие факторы практически никакой роли не играют. Даже можно сказать, что все факторы влияют на искомый **y** не больше, чем на `12%` каждый!*

Давайте поступим так: найдем среднее между всеми факторами в датасете, и оставим только те, которые больше или равны среднему между ними!

```python
mean = data.corr()['y'].mean()  # Среднее между корр. факторов

corr = data.corr()['y']  # Сама корреляция
corr = corr[(corr >= mean_corr) | (corr <= -mean_corr)]  # Убираем остальные
```

<br />

**Казалось бы**, что метод хорош, однако, после тренировки именно таким методом, я заметил, что лучше мне оставить чуть больше факторов, чем я сделал при помощи среднего между значениями `pandas.DataFrame.corr()` :)

В итоге, я решил забрать те факторы, которые влияют на искомый *y* больше, чем на *3%*

___

Убрав сам *y* из списка индексов для корреляции, у нас получился следующий список факторов, играющий хорошую роль в предсказании значения *y*:

![](https://github.com/plugg1N/aiijc-team-task-2023/blob/main/Images/end_corr.png?raw=true)

Потом мы быстренько убираем `Na` значения из списка наших объектов:
```python
X_y = X_y.dropna()
```

И в итоге, у нас 225000 значений для каждого фактора!

<br />

## Готовим данные к подбору модели МО

Проблема с дисбалансом классов - осталась. Поэтому, давайте это исправим, используя [ADASYN](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html).

- **ADASYN** - это улучшенная версия *oversampling*-овой техники [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) Обе эти техники позволяют убрать дисбаланс между двумя классами, посредством наполнения класса меньшинства синтетическими данными. Эти данные создаются опираясь на n-ближайших соседей к каждому фактору

___

> *Почему именно этот метод, а не другие способы убирания дисбаланса? *

Все очень просто! У нас есть два других способа убрать дисбаланс:

-  **RandomOverSampler** - просто пополняет класс меньшинства похожими или такими же данными факторов

МИНУС: минусом данного способа является `overfitting`, который может появится по двум причинам: слишком сильный дисбаланс - а значит нужно будет много рандомных инстанций создавать; будет `оверфиттинг`, т.к. мы даем модели слишком много похожих данных

<br />

- **UnderSampling** - убирает инстанции класса большинства

МИНУС: разница между меньшинством и большинством - велика -- мы потеряем СЛИШКОМ много данных

___

> *Мы применили **ADASYN** к нашему Датафрейму, как теперь обстоят дела с данными?*

![](https://github.com/plugg1N/aiijc-team-task-2023/blob/main/Images/adasyn.png?raw=true)

- Можно заметить, что теперь, вместо разницы:
  
$$ \Large ClassDist_1= \frac {32337} {192663} = 0.1678... $$

- У нас **теперь**:
  
$$ \Large ClassDist_2 = \frac {191627} {192663} = 0.9946... $$

То есть, баланс восстановлен почти на все 100% *(99.5%)*. Нас это полностью устраивает

___

Делим наш *X* и *y* на под-выборки **train** и местный **test**. Почему местный тест? Потому что на самом деле - это под-выборка **val**, но так как мы знаем, что происходит на самом деле, то мы можем воспользоваться привычным нам вариантом и назвать под-выборку **test**

![](https://github.com/plugg1N/aiijc-team-task-2023/blob/main/Images/big_bars2.png?raw=true)

___

Далее, мы применяем [minMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) к каждому из *X* под-выборок, чтобы упростить работу нашей модели и стандартизировать значения в промежуток $[0, 1]$, по этой формуле:

<br />


$$ \Large X \text std  = \frac {X - X\text min} {Xmax - Xmin} $$
$$ \Large Xscaled = Xstd * ( Xmax - Xmin ) + Xmin $$

<br />

- Данные получаются в таком формате: 

![](https://github.com/plugg1N/aiijc-team-task-2023/blob/main/Images/scaled.png?raw=true)

<br />


## Начинаем подбирать модели МО

Самая тяжелая и значимая часть работы, так как именно на этом этапе станет известно, сделал ли я правильные выборы, или все же нет

Я решил начать подбор вариантов от самых очевидных, до самых практичных. Таким образом я избавлюсь от примитивных моделей и в конце перейду к более тяжелым архитектурам

___

# Список постоянно обновляется!

- [x]  Метод k-ближайших соседей (K-Nearest Neighbors) -- **0.80 (K_neibours=5) (F1-score)**;

- [ ]  Классификатор дерева решений (Decision Tree Classifier) / Случайный лес (Random Forests);

- [x]  Наивный байесовский метод (Naive Bayes) -- **0.65 (F1-score)** 

- [ ]  Линейный дискриминантный анализ (Linear Discriminant Analysis);

- [x]  Логистическая регрессия (Logistic Regression)  -- **0.69 (F1-score)**

- [ ]  Глубокое обучение и нейронные сети;

___

